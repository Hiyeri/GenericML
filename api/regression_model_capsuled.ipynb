{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "import threading\n",
    "from flask import Flask, flash, request, redirect, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score, mean_squared_log_error\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_feature_selection_transformation(X, y, target, ordinal_feature, route, path):\n",
    "    \n",
    "    def train_num_feature_selection(X_num):\n",
    "        # saleprice correlation matrix\n",
    "        k_num = round(len(X_num.columns) / 2)\n",
    "        corrmat = X_num.corr()\n",
    "        X_num_fs = corrmat.nlargest(k_num, target)[target].index\n",
    "    \n",
    "        # check for multicollinearity\n",
    "        # if two features are strongly correlated with each other (>= 0.7) \n",
    "        # the feature with the lower correlation with the target variable is dropped\n",
    "        multicorr = {}\n",
    "        k = len(corrmat)\n",
    "        for feature in corrmat:\n",
    "            i = 1\n",
    "            if feature != target:\n",
    "                while i < k - 1:\n",
    "                    if corrmat[feature][i] >= 0.7 and feature != corrmat.index[i]:\n",
    "                        multicorr[feature] = corrmat.index[i], corrmat[feature][i]\n",
    "                    i = i + 1\n",
    "        \n",
    "        # delete duplicates\n",
    "        corr_scores = []\n",
    "        for feature in list(multicorr.keys()):\n",
    "            if multicorr[feature][1] in corr_scores:\n",
    "                del multicorr[feature]\n",
    "            else:\n",
    "                corr_scores.append(multicorr[feature][1])\n",
    "        \n",
    "        dropped_features = []\n",
    "        # remove the feature with the lower correlation coefficient (pearson) \n",
    "        for feature1, feature2 in multicorr.items():\n",
    "            if corrmat[target][feature1] < corrmat[target][feature2[0]]:\n",
    "                dropped_features.append(feature1)\n",
    "            else:\n",
    "                dropped_features.append(feature2[0])\n",
    "    \n",
    "        # drop the features from X_num dataframe\n",
    "        for feature in X_num:\n",
    "            if feature in dropped_features:\n",
    "                X_num = X_num.drop(feature, axis = 1)\n",
    "        drop_corr_features = X_num.columns.difference(X_num_fs)\n",
    "        X_num.drop(X_num.columns.difference(X_num_fs), 1, inplace = True)\n",
    "        \n",
    "        return (X_num, dropped_features, drop_corr_features)\n",
    "    \n",
    "    \n",
    "    def train_cat_feature_selection(X_cat, X_cat_enc):\n",
    "        # feature selection on categorical data\n",
    "        k_cat = round(len(X_cat.columns) / 2)\n",
    "        fs = SelectKBest(f_classif, k_cat)\n",
    "        fs.fit(X_cat_enc, y) # save!!\n",
    "        X_cat_fs = fs.transform(X_cat_enc)\n",
    "        X_cat_enc = pd.DataFrame(X_cat_fs)\n",
    "        \n",
    "        return (X_cat_enc, fs)\n",
    "    \n",
    "    def predict_num_feature_selection(X_num):\n",
    "        directory = path + '/fs_values.pkl'\n",
    "        with open(directory, 'rb') as file:\n",
    "            drop_multicoll_features, drop_corr_features = pickle.load(file)[:2]\n",
    "            \n",
    "        X_num = X_num.drop(drop_multicoll_features, axis = 1) \n",
    "        X_num.drop(drop_corr_features, 1, inplace = True)\n",
    "        \n",
    "        return X_num\n",
    "    \n",
    "    def predict_cat_feature_selection(X_cat_enc):\n",
    "        directory = path + '/fs_values.pkl'\n",
    "        with open(directory, 'rb') as file:\n",
    "            selected_cat_features, dummy = pickle.load(file)[2:4]\n",
    "            \n",
    "        X_cat_fs = selected_cat_features.transform(X_cat_enc)\n",
    "        X_cat_enc = pd.DataFrame(X_cat_fs)\n",
    "        \n",
    "        return X_cat_enc\n",
    "    \n",
    "    # split features\n",
    "    num_features = []\n",
    "    cat_features = []\n",
    "    X_num = pd.DataFrame()\n",
    "    X_cat = pd.DataFrame()\n",
    "    \n",
    "    for feature in X:\n",
    "        if X[feature].dtypes == np.int or X[feature].dtypes == np.float:\n",
    "            num_features.append(feature)\n",
    "        else:\n",
    "            cat_features.append(feature)\n",
    "    \n",
    "    # impute using only numerical features\n",
    "    if num_features and not all(elem == target for elem in num_features):\n",
    "        X = X.reset_index(drop = True)\n",
    "        imp = IterativeImputer(max_iter = 10, random_state = 42)\n",
    "        imp.fit(X[num_features])\n",
    "        X[num_features] = imp.transform(X[num_features])\n",
    "        X_num = X.drop(cat_features, axis = 1)\n",
    "    \n",
    "    # impute using only categorical features\n",
    "    if cat_features:\n",
    "        imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "        X[cat_features] = imp.fit_transform(X[cat_features].astype(str))\n",
    "        X_cat = X.drop(num_features, axis = 1)\n",
    "        \n",
    "    # get column count\n",
    "    if num_features and not all(elem == target for elem in num_features):\n",
    "        num_shape = X_num.shape[1]\n",
    "    else:\n",
    "        num_shape = 0\n",
    "    \n",
    "    if cat_features:\n",
    "        cat_shape = X_cat.shape[1]\n",
    "    else:\n",
    "        cat_shape = 0\n",
    "    \n",
    "    # feature selection numerical features\n",
    "    if route == '/train':\n",
    "        if num_features and not all(elem == target for elem in num_features) and not num_shape <= 10:\n",
    "            X_num, drop_multicoll_features, drop_corr_features = train_num_feature_selection(X_num)\n",
    "        else:\n",
    "            drop_multicoll_features = []\n",
    "            drop_corr_features = []\n",
    "            selected_num_features = None\n",
    "    elif route == '/predict':\n",
    "        if num_features and not num_shape <= 10:\n",
    "            X_num = predict_num_feature_selection(X_num)\n",
    "        \n",
    "    # encode ordinal features (dummy variables)\n",
    "    if ordinal_feature is not None and ordinal_feature in X_num:\n",
    "        ord_data = [ordinal_feature]\n",
    "        X_num = pd.get_dummies(X_num, columns = ord_data, drop_first = True)\n",
    "\n",
    "    # encode categorical features\n",
    "    if cat_features:\n",
    "        enc = OrdinalEncoder()\n",
    "        enc.fit(X_cat)\n",
    "        X_cat_enc = enc.transform(X_cat)\n",
    "    \n",
    "    # feature selection caterorical features\n",
    "    if route == '/train':\n",
    "        if cat_features and not cat_shape <= 10:\n",
    "            X_cat_enc, selected_cat_features = train_cat_feature_selection(X_cat, X_cat_enc)\n",
    "        else:\n",
    "            selected_cat_features = None\n",
    "    elif route == '/predict':\n",
    "        if cat_features and not cat_shape <= 10:\n",
    "            X_cat_enc = predict_cat_feature_selection(X_cat_enc)\n",
    "    \n",
    "    # concatenate numerical and categorical features\n",
    "    if cat_features and num_features and not all(elem == target for elem in num_features):\n",
    "        df_cat = pd.DataFrame(X_cat_enc, index = list(range(len(X.index))))\n",
    "        df_num = pd.DataFrame(X_num, index = list(range(len(X.index))))\n",
    "        X = pd.concat([df_cat, df_num], axis = 1, sort = False)\n",
    "    elif cat_features:\n",
    "        X = pd.DataFrame(X_cat_enc)\n",
    "    elif num_features:\n",
    "        X = pd.DataFrame(X_num)\n",
    "    \n",
    "    if route == '/train':\n",
    "        # serialize feature selection values\n",
    "        fs_values = [drop_multicoll_features, drop_corr_features, selected_cat_features, ordinal_feature, target]\n",
    "        directory = path + '/fs_values.pkl'\n",
    "        with open(directory, 'wb') as file:\n",
    "            pickle.dump(fs_values, file)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_randomforestregress(X, y, target):\n",
    "    # build model\n",
    "    if target in X:\n",
    "        X = X.drop(target, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators = 800, min_samples_split = 2, min_samples_leaf = 1, \n",
    "      max_features = 'log2', max_depth = 70, bootstrap = False)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # quantify quality of prediction\n",
    "    y_predict = rf.predict(X_test)\n",
    "    r_2_score = abs(r2_score(y_test, y_predict))\n",
    "    model = (rf, r_2_score)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linearregress(X, y, target):\n",
    "    # build model\n",
    "    if target in X:\n",
    "        X = X.drop(target, axis = 1)\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state = 42)\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # quantify quality of prediction\n",
    "    y_predict = reg.predict(X_test)\n",
    "    r_2_score = abs(r2_score(y_test, y_predict))\n",
    "    \n",
    "    model = (reg, r_2_score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(path, target, ordinal_feature, route):\n",
    "    def predict_regress(feature_engineering, y, target, path):\n",
    "        rf, rf_r2 = predict_randomforestregress(feature_engineering, y, target)\n",
    "        reg, reg_r2 = predict_linearregress(feature_engineering, y, target)\n",
    "        \n",
    "        best_score = max([rf_r2, reg_r2])\n",
    "        \n",
    "        # save best model on disk\n",
    "        directory_model = path + '/model.pkl'\n",
    "        if best_score == rf_r2:\n",
    "            with open(directory_model, 'wb') as file:\n",
    "                pickle.dump(rf, file)\n",
    "                model = 'RandomForestRegressor'\n",
    "                scoring_param = 'r2 score'\n",
    "                return (model, scoring_param, rf_r2)\n",
    "        elif best_score == reg_r2:\n",
    "            with open(directory_model, 'wb') as file:\n",
    "                pickle.dump(reg, file)\n",
    "                model = 'LinearRegression'\n",
    "                scoring_param = 'r2 score'\n",
    "                return (model, scoring_param, reg_r2)\n",
    "        \n",
    "    directory = path + '/train_data.pkl'\n",
    "    with open(directory, 'rb') as file:\n",
    "        train_data = pickle.load(file)\n",
    "\n",
    "    features = list(train_data)\n",
    "    X = train_data[features]\n",
    "    y = train_data[target]\n",
    "\n",
    "    feature_engineering = regress_feature_selection_transformation(X, y, target, ordinal_feature, route, path)\n",
    "    model, scoring_param, best_score = predict_regress(feature_engineering, y, target, path) \n",
    "    \n",
    "    model_stats = [model, scoring_param, best_score, path]\n",
    "    directory = path + '/model_stats.pkl'\n",
    "    with open(directory, 'wb') as file:\n",
    "        pickle.dump(model_stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    path = 'model_name'\n",
    "    if os.path.exists(path):\n",
    "        return json.dumps({'Error': \"Model already exists\"})\n",
    "    else:\n",
    "        train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/house-prices-advanced-regression-techniques\" +\n",
    "                                               \"/train.csv\"), index_col = [0])\n",
    "        # train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/miscellaneous/train_Xnum_ynum.csv\"), index_col = [0])\n",
    "        # train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/miscellaneous/train_Xcat_ynum.csv\"), index_col = [0])\n",
    "        \n",
    "        # select features and target variable\n",
    "        target = 'SalePrice'\n",
    "        # ordinal_feature = 'OrdinalQual'\n",
    "        ordinal_feature = None\n",
    "        route = '/train'\n",
    "        \n",
    "        os.mkdir(path)\n",
    "        directory = path + '/train_data.pkl'\n",
    "        with open(directory, 'wb') as file:\n",
    "            pickle.dump(train_data, file)\n",
    "        \n",
    "        download_thread = threading.Thread(target = build_model, args = (path, target, ordinal_feature, route,))\n",
    "        download_thread.start()\n",
    "        return json.dumps({'Message': 'Successful'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Message\": \"Successful\"}'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    test_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/house-prices-advanced-regression-techniques\" +\n",
    "                                                \"/test.csv\"), index_col = [0])\n",
    "    # test_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/miscellaneous/test_Xcat_ynum.csv\"), index_col = [0])\n",
    "    # test_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/miscellaneous/test_Xnum_ynum.csv\"), index_col = [0])\n",
    "    route = '/predict'\n",
    "    path = 'model_name'\n",
    "    \n",
    "    directory_fs = path + '/fs_values.pkl'\n",
    "    directory_model = path + '/model.pkl'\n",
    "    with open(directory_fs, 'rb') as file:\n",
    "        ordinal_feature, target = pickle.load(file)[3:]\n",
    "    with open(directory_model, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # nur bei sale_price\n",
    "    # test_data = test_data.reset_index()\n",
    "    \n",
    "    feature_engineering = regress_feature_selection_transformation(test_data, None, None, ordinal_feature, route, path)\n",
    "    y_predict = model.predict(feature_engineering)\n",
    "    \n",
    "    df_1stcolumn = pd.DataFrame(test_data.iloc[:,0])\n",
    "    df_prediction = pd.DataFrame({target: y_predict})\n",
    "    df_1stcolumn = df_1stcolumn.reset_index(drop = True) # super important\n",
    "    df_prediction = df_prediction.reset_index(drop = True) # super important\n",
    "    output = df_1stcolumn.merge(df_prediction, left_index = True, right_index = True)\n",
    "    result = output.to_json(orient = 'records')\n",
    "    parsed = json.loads(result)\n",
    "    \n",
    "    return json.dumps(parsed, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status():\n",
    "    model_name = 'model_name'\n",
    "    directory = model_name + '/model_stats.pkl'\n",
    "    if os.path.exists(directory):\n",
    "        with open(directory, 'rb') as file:\n",
    "            model, scoring_param, best_score, path = pickle.load(file)\n",
    "            return json.dumps({'model': model, scoring_param :best_score, 'model name': path}, sort_keys = True, indent = 4, separators=(',', ': '))\n",
    "    else:\n",
    "        return json.dumps({'Message': 'Model is not available yet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"model\": \"RandomForestRegressor\",\\n    \"model name\": \"model_name\",\\n    \"r2 score\": 0.8987830720229072\\n}'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# def delete():\n",
    "#     target = \"model_name\"\n",
    "#     if os.path.exists(target):\n",
    "#         shutil.rmtree(target, ignore_errors = True)\n",
    "#         return json.dumps({'Message': \"Directory successfully removed\"})\n",
    "#     else:\n",
    "#         return json.dumps({'Error': \"Directory does not exist\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass k=22 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
