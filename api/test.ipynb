{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score, mean_squared_log_error\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/house-prices-advanced-regression-techniques/\" + \n",
    "                                            \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_data)\n",
    "X = train_data[features]\n",
    "y = train_data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for numeric features train_data\n",
    "num_features = []\n",
    "cat_features = []\n",
    "for feature in X:\n",
    "    if X[feature].dtypes == np.int or X[feature].dtypes == np.float:\n",
    "        num_features.append(feature)\n",
    "    else:\n",
    "        cat_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = pd.concat([X[num_features], X['SalePrice']], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 38 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   OverallQual    1460 non-null   int64  \n",
      " 5   OverallCond    1460 non-null   int64  \n",
      " 6   YearBuilt      1460 non-null   int64  \n",
      " 7   YearRemodAdd   1460 non-null   int64  \n",
      " 8   MasVnrArea     1452 non-null   float64\n",
      " 9   BsmtFinSF1     1460 non-null   int64  \n",
      " 10  BsmtFinSF2     1460 non-null   int64  \n",
      " 11  BsmtUnfSF      1460 non-null   int64  \n",
      " 12  TotalBsmtSF    1460 non-null   int64  \n",
      " 13  1stFlrSF       1460 non-null   int64  \n",
      " 14  2ndFlrSF       1460 non-null   int64  \n",
      " 15  LowQualFinSF   1460 non-null   int64  \n",
      " 16  GrLivArea      1460 non-null   int64  \n",
      " 17  BsmtFullBath   1460 non-null   int64  \n",
      " 18  BsmtHalfBath   1460 non-null   int64  \n",
      " 19  FullBath       1460 non-null   int64  \n",
      " 20  HalfBath       1460 non-null   int64  \n",
      " 21  BedroomAbvGr   1460 non-null   int64  \n",
      " 22  KitchenAbvGr   1460 non-null   int64  \n",
      " 23  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 24  Fireplaces     1460 non-null   int64  \n",
      " 25  GarageYrBlt    1379 non-null   float64\n",
      " 26  GarageCars     1460 non-null   int64  \n",
      " 27  GarageArea     1460 non-null   int64  \n",
      " 28  WoodDeckSF     1460 non-null   int64  \n",
      " 29  OpenPorchSF    1460 non-null   int64  \n",
      " 30  EnclosedPorch  1460 non-null   int64  \n",
      " 31  3SsnPorch      1460 non-null   int64  \n",
      " 32  ScreenPorch    1460 non-null   int64  \n",
      " 33  PoolArea       1460 non-null   int64  \n",
      " 34  MiscVal        1460 non-null   int64  \n",
      " 35  MoSold         1460 non-null   int64  \n",
      " 36  YrSold         1460 non-null   int64  \n",
      " 37  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35)\n",
      "memory usage: 433.6 KB\n"
     ]
    }
   ],
   "source": [
    "# X_new.info()\n",
    "X = X[num_features]\n",
    "# X = X.drop('SalePrice', axis = 1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new.to_json('data/miscellaneous/Xcat_ynum.json')\n",
    "# X_new.to_csv('data/miscellaneous/Xcat_ynum.csv')\n",
    "X.to_json('data/miscellaneous/train_Xnum_ynum.json')\n",
    "X_new.to_csv('data/miscellaneous/train_Xnum_ynum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yom\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "if cat_features:\n",
    "    print(\"hi\")\n",
    "else:\n",
    "    print(\"yom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9524449313129651\n",
      "RMSLE: 0.09987353221616248\n"
     ]
    }
   ],
   "source": [
    "# check for numeric features train_data\n",
    "train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/miscellaneous/pure_num_data.csv\"))\n",
    "target = 'SalePrice'\n",
    "ordinal_feature = 'OverallQual'\n",
    "\n",
    "features = list(train_data)\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "num_features = []\n",
    "cat_features = []\n",
    "for feature in X:\n",
    "    if X[feature].dtypes == np.int or X[feature].dtypes == np.float:\n",
    "        num_features.append(feature)\n",
    "    else:\n",
    "        cat_features.append(feature)\n",
    "\n",
    "X = X.reset_index()\n",
    "# if num_features is not empty\n",
    "# impute using only numerical features\n",
    "if num_features:\n",
    "    imp = IterativeImputer(max_iter = 10, random_state = 42)\n",
    "    imp.fit(X[num_features])\n",
    "    X[num_features] = imp.transform(X[num_features])\n",
    "    X_num = X.drop(cat_features, axis = 1)\n",
    "\n",
    "# if cat_features is not empty\n",
    "# impute using only categorical features\n",
    "if cat_features:\n",
    "    imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "    X[cat_features] = imp.fit_transform(X[cat_features].astype(str))\n",
    "    X_cat = X.drop(num_features, axis = 1)\n",
    "\n",
    "# saleprice correlation matrix\n",
    "k_num = round(len(X_num.columns) / 2)\n",
    "corrmat = X_num.corr()\n",
    "X_num_fs = corrmat.nlargest(k_num, target)[target].index\n",
    "\n",
    "# check for multicollinearity\n",
    "# if two features are strongly correlated with each other (>= 0.7) \n",
    "# the feature with the lower correlation with the target variable is dropped\n",
    "multicorr = {}\n",
    "k = len(corrmat)\n",
    "for feature in corrmat:\n",
    "    i = 1\n",
    "    if feature != target:\n",
    "        while i < k - 1:\n",
    "            if corrmat[feature][i] >= 0.7 and feature != corrmat.index[i]:\n",
    "                multicorr[feature] = corrmat.index[i], corrmat[feature][i]\n",
    "            i = i + 1\n",
    "    \n",
    "# delete duplicates\n",
    "corr_scores = []\n",
    "for feature in list(multicorr.keys()):\n",
    "    if multicorr[feature][1] in corr_scores:\n",
    "        del multicorr[feature]\n",
    "    else:\n",
    "        corr_scores.append(multicorr[feature][1])\n",
    "        \n",
    "# remove the feature with the lower correlation coefficient (pearson)\n",
    "dropped_features = [] \n",
    "for feature1, feature2 in multicorr.items():\n",
    "    if corrmat[target][feature1] < corrmat[target][feature2[0]]:\n",
    "        dropped_features.append(feature1)\n",
    "    else:\n",
    "        dropped_features.append(feature2[0])\n",
    "\n",
    "# drop the features from X_num dataframe\n",
    "for feature in X_num:\n",
    "    if feature in dropped_features:\n",
    "        X_num = X_num.drop(feature, axis = 1) \n",
    "X_num.drop(X_num.columns.difference(X_num_fs), 1, inplace = True)\n",
    "\n",
    "drop_multicoll_features = dropped_features\n",
    "drop_corr_features = X_num.columns.difference(X_num_fs)\n",
    "\n",
    "# encode ordinal features (dummy variables)\n",
    "ord_data = [ordinal_feature]\n",
    "X_num = pd.get_dummies(X_num, columns = ord_data, drop_first = True)\n",
    "\n",
    "# if cat_features is not empty\n",
    "# encode categorical features\n",
    "if cat_features:\n",
    "    enc = OrdinalEncoder()\n",
    "    enc.fit(X_cat)\n",
    "    X_cat_enc = enc.transform(X_cat)\n",
    "    \n",
    "    # feature selection on categorical data\n",
    "    k_cat = round(len(X_cat.columns) / 2)\n",
    "    fs = SelectKBest(f_regression, k_cat)\n",
    "    fs.fit(X_cat_enc, y) # save!!\n",
    "    X_cat_fs = fs.transform(X_cat_enc)\n",
    "    X_cat_enc = pd.DataFrame(X_cat_fs)\n",
    "    \n",
    "    # if cat_features and num_features are not empty\n",
    "    # concatenate numerical and categorical features\n",
    "    if cat_features and num_features:\n",
    "        df_cat = pd.DataFrame(X_cat_enc, index = list(range(len(X.index))))\n",
    "        df_num = pd.DataFrame(X_num, index = list(range(len(X.index))))\n",
    "        X = pd.concat([df_cat, df_num], axis = 1, sort = False)\n",
    "        X = X.drop([target], axis = 1)\n",
    "    elif cat_features:\n",
    "        X = pd.DataFrame(X_cat_enc)\n",
    "    elif num_features:\n",
    "        X = pd.DataFrame(X_num)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "rf = RandomForestRegressor(n_estimators = 800, min_samples_split = 2, min_samples_leaf = 1, \n",
    "                            max_features = 'log2', max_depth = 70, bootstrap = False)\n",
    "rf.fit(X_train, y_train)\n",
    "# quantify quality of prediction\n",
    "y_predict = rf.predict(X_test)\n",
    "r_2_score = r2_score(y_test, y_predict)\n",
    "rmsle = math.sqrt(mean_squared_log_error(y_test, y_predict))\n",
    "ret_stmt = 'R^2 Score: ' + str(r_2_score) + '\\n' + 'RMSLE: ' + str(rmsle)\n",
    "\n",
    "print(ret_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/titanic_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_data)\n",
    "X = train_data[features]\n",
    "y = train_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for numeric features train_data\n",
    "num_features = []\n",
    "cat_features = []\n",
    "for feature in X:\n",
    "    if X[feature].dtypes == np.int or X[feature].dtypes == np.float:\n",
    "        num_features.append(feature)\n",
    "    else:\n",
    "        cat_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.concat([X[cat_features], X['Survived']], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.to_json('data/miscellaneous/pure_cat_data.json')\n",
    "X_new.to_csv('data/miscellaneous/pure_cat_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_example = (0, 1, 2, 3, 4)\n",
    "tuple_example[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
