{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score, mean_squared_log_error\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_feature_selection_transformation(X, y, target, ordinal_feature, route):\n",
    "    \n",
    "    def train_num_feature_selection(X_num):\n",
    "        # feature selection on numerical data\n",
    "        k_num = round(len(X_num.columns) / 2)\n",
    "        fs = SelectKBest(f_classif, k_num)\n",
    "        fs.fit(X_num, y) # save!!\n",
    "        X_num_fs = fs.transform(X_num)\n",
    "        return (X_num_fs, fs)\n",
    "        \n",
    "    def train_cat_feature_selection(X_cat, X_cat_enc):\n",
    "        # feature selection on categorical data\n",
    "        k_cat = round(len(X_cat.columns) / 2)\n",
    "        fs = SelectKBest(chi2, k_cat)\n",
    "        fs.fit(X_cat_enc, y) # save!!\n",
    "        X_cat_fs = fs.transform(X_cat_enc)\n",
    "        X_cat_enc = pd.DataFrame(X_cat_fs)\n",
    "        return (X_cat_enc, fs)\n",
    "    \n",
    "    def predict_num_feature_selection(X_num):\n",
    "        with open('fs_values.pkl', 'rb') as file:\n",
    "            selected_num_features, dummy = pickle.load(file)[0:2]\n",
    "            \n",
    "        X_num_fs = selected_num_features.transform(X_num)\n",
    "        X_num = pd.DataFrame(X_num_fs)\n",
    "        \n",
    "        return X_num\n",
    "    \n",
    "    def predict_cat_feature_selection(X_cat_enc):\n",
    "        with open('fs_values.pkl', 'rb') as file:\n",
    "            dummy, selected_cat_features = pickle.load(file)[0:2]\n",
    "            \n",
    "        X_cat_fs = selected_cat_features.transform(X_cat_enc)\n",
    "        X_cat_enc = pd.DataFrame(X_cat_fs)\n",
    "        \n",
    "        return X_cat_enc\n",
    "    \n",
    "    # split features\n",
    "    num_features = []\n",
    "    cat_features = []\n",
    "    X_num = pd.DataFrame()\n",
    "    X_cat = pd.DataFrame()\n",
    "    \n",
    "    for feature in X:\n",
    "        if X[feature].dtypes == np.int or X[feature].dtypes == np.float:\n",
    "            num_features.append(feature)\n",
    "        else:\n",
    "            cat_features.append(feature)\n",
    "    \n",
    "    # impute using only numerical features\n",
    "    if num_features:\n",
    "        X = X.reset_index(drop = True)\n",
    "        imp = IterativeImputer(max_iter = 10, random_state = 42)\n",
    "        imp.fit(X[num_features])\n",
    "        X[num_features] = imp.transform(X[num_features])\n",
    "        X_num = X.drop(cat_features, axis = 1)\n",
    "    \n",
    "    # impute using only categorical features\n",
    "    if cat_features and not all(elem == target for elem in cat_features):\n",
    "        imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "        X[cat_features] = imp.fit_transform(X[cat_features].astype(str))\n",
    "        X_cat = X.drop(num_features, axis = 1)\n",
    "        \n",
    "    # get column count\n",
    "    if not X_num.empty:\n",
    "        num_shape = X_num.shape[1]\n",
    "    else:\n",
    "        num_shape = 0\n",
    "    \n",
    "    if not X_cat.empty:\n",
    "        cat_shape = X_cat.shape[1]\n",
    "    else:\n",
    "        cat_shape = 0\n",
    "    \n",
    "    # drop target\n",
    "    if target in X_num:\n",
    "        X_num = X_num.drop(target, axis = 1)\n",
    "    if target in X_cat:\n",
    "        X_cat = X_cat.drop(target, axis = 1)\n",
    "    \n",
    "    # feature selection on num_features\n",
    "    if route == '/train':\n",
    "        if num_features and not num_shape <= 10:\n",
    "            X_num, selected_num_features = train_num_feature_selection(X_num)\n",
    "        else:\n",
    "            selected_num_features = None\n",
    "    if route == '/predict':\n",
    "        if num_features and not num_shape <= 10:\n",
    "            X_num = predict_num_feature_selection(X_num)\n",
    "    \n",
    "    # encode ordinal features (dummy variables)\n",
    "    if ordinal_feature is not None:\n",
    "        ord_data = [ordinal_feature]\n",
    "        X_num = pd.get_dummies(X_num, columns = ord_data, drop_first = True)\n",
    "    \n",
    "    if cat_features:\n",
    "        enc = OrdinalEncoder()\n",
    "        enc.fit(X_cat)\n",
    "        X_cat_enc = enc.transform(X_cat)\n",
    "    \n",
    "    # feature selection on cat_features\n",
    "    if route == '/train':\n",
    "        if cat_features and not cat_shape <= 10:\n",
    "            X_cat_enc, selected_cat_features = train_cat_feature_selection(X_cat, X_cat_enc)\n",
    "        else:\n",
    "            selected_cat_features = None\n",
    "    if route == '/predict':\n",
    "        if cat_features and not cat_shape <= 10:\n",
    "            X_cat_enc = predict_cat_feature_selection(X_cat_enc)\n",
    "    \n",
    "    # concatenate numerical and categorical features\n",
    "    if num_features and cat_features:\n",
    "        df_cat = pd.DataFrame(X_cat_enc, index = list(range(len(X.index))))\n",
    "        df_num = pd.DataFrame(X_num, index = list(range(len(X.index))))\n",
    "        X = pd.concat([df_cat, df_num], axis = 1, sort = False)\n",
    "    elif cat_features:\n",
    "        X = pd.DataFrame(X_cat_enc)\n",
    "    elif num_features:\n",
    "        X = pd.DataFrame(X_num)\n",
    "    \n",
    "    if route == '/train':\n",
    "        # serialize feature selection values\n",
    "        fs_values = [selected_num_features, selected_cat_features, ordinal_feature, target]\n",
    "        with open('fs_values.pkl', 'wb') as file:\n",
    "            pickle.dump(fs_values, file)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_randomforestclass(X, y, target):\n",
    "    if target in X:\n",
    "        X = X.drop(target, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100, max_depth = None) \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # quantifying the quality of prediction\n",
    "    y_predict = rf.predict(X_test)\n",
    "    acc_score = abs(accuracy_score(y_test, y_predict))\n",
    "    \n",
    "    model = (rf, acc_score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logisticregress(X, y, target):\n",
    "    if target in X:\n",
    "        X = X.drop(target, axis = 1)\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state = 42)\n",
    "    \n",
    "    log_reg = LogisticRegression(random_state = 42) \n",
    "    log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # quantifying the quality of prediction\n",
    "    y_predict = log_reg.predict(X_test)\n",
    "    acc_score = abs(accuracy_score(y_test, y_predict))\n",
    "    \n",
    "    model = (log_reg, acc_score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    def predict_class(feature_engineering, y, target):\n",
    "        rf, rf_acc = predict_randomforestclass(feature_engineering, y, target)\n",
    "        log_reg, log_acc = predict_logisticregress(feature_engineering, y, target)\n",
    "        \n",
    "        best_score = max([rf_acc, log_acc])\n",
    "\n",
    "        # save best model on disk\n",
    "        if best_score == rf_acc:\n",
    "            with open('model.pkl', 'wb') as file:\n",
    "                pickle.dump(rf, file)\n",
    "                model = 'RandomForestClassifier: '\n",
    "                return (model, rf_acc)\n",
    "        elif best_score == log_acc:\n",
    "            with open('model.pkl', 'wb') as file:\n",
    "                pickle.dump(log_reg, file)\n",
    "                model = 'LinearRegression: '\n",
    "                return (model, log_acc)\n",
    "    \n",
    "    train_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/titanic_train.csv\"), index_col = [0])\n",
    "    \n",
    "    # select features and target variable\n",
    "    target = 'Survived'\n",
    "    ordinal_feature = None\n",
    "    route = '/train'\n",
    "    \n",
    "    features = list(train_data)\n",
    "    X = train_data[features]\n",
    "    y = train_data[target]\n",
    "    \n",
    "    # only for iris\n",
    "    # X = X.drop('Id', axis = 1)\n",
    "\n",
    "    feature_engineering = class_feature_selection_transformation(X, y, target, ordinal_feature, route)\n",
    "    model, best_score = predict_class(feature_engineering, y, target)\n",
    "    prediction = model + 'Accuracy Score: ' + str(best_score) \n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestClassifier: Accuracy Score: 0.852017937219731'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    \n",
    "    test_data = pd.read_csv(os.path.expanduser(\"~/Desktop/Projects/api/data/titanic_test.csv\"), index_col = [0])\n",
    "    route = '/predict'\n",
    "    \n",
    "    with open('fs_values.pkl', 'rb') as file:\n",
    "        ordinal_feature, target = pickle.load(file)[2:]\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "        \n",
    "    # test_data = test_data.reset_index(drop = True)\n",
    "    \n",
    "    # nur bei iris\n",
    "    # test_data = test_data.drop('Species', axis = 1)\n",
    "    \n",
    "    feature_engineering = class_feature_selection_transformation(test_data, None, None, ordinal_feature, route)\n",
    "    y_predict = model.predict(feature_engineering)\n",
    "    \n",
    "    df_features = pd.DataFrame(test_data)\n",
    "    df_prediction = pd.DataFrame({target: y_predict})\n",
    "    output = pd.concat([df_features, df_prediction], axis = 1, sort = False)\n",
    "    output.to_csv('prediction.csv', index = False)\n",
    "    output.describe()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pclass                          Name     Sex   Age  SibSp  Parch  \\\n",
       "0        NaN                           NaN     NaN   NaN    NaN    NaN   \n",
       "1        NaN                           NaN     NaN   NaN    NaN    NaN   \n",
       "2        NaN                           NaN     NaN   NaN    NaN    NaN   \n",
       "3        NaN                           NaN     NaN   NaN    NaN    NaN   \n",
       "4        NaN                           NaN     NaN   NaN    NaN    NaN   \n",
       "...      ...                           ...     ...   ...    ...    ...   \n",
       "1305     3.0            Spector, Mr. Woolf    male   NaN    0.0    0.0   \n",
       "1306     1.0  Oliva y Ocana, Dona. Fermina  female  39.0    0.0    0.0   \n",
       "1307     3.0  Saether, Mr. Simon Sivertsen    male  38.5    0.0    0.0   \n",
       "1308     3.0           Ware, Mr. Frederick    male   NaN    0.0    0.0   \n",
       "1309     3.0      Peter, Master. Michael J    male   NaN    1.0    1.0   \n",
       "\n",
       "                  Ticket      Fare Cabin Embarked  Survived  \n",
       "0                    NaN       NaN   NaN      NaN       0.0  \n",
       "1                    NaN       NaN   NaN      NaN       0.0  \n",
       "2                    NaN       NaN   NaN      NaN       0.0  \n",
       "3                    NaN       NaN   NaN      NaN       1.0  \n",
       "4                    NaN       NaN   NaN      NaN       1.0  \n",
       "...                  ...       ...   ...      ...       ...  \n",
       "1305           A.5. 3236    8.0500   NaN        S       NaN  \n",
       "1306            PC 17758  108.9000  C105        C       NaN  \n",
       "1307  SOTON/O.Q. 3101262    7.2500   NaN        S       NaN  \n",
       "1308              359309    8.0500   NaN        S       NaN  \n",
       "1309                2668   22.3583   NaN        C       NaN  \n",
       "\n",
       "[836 rows x 11 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
